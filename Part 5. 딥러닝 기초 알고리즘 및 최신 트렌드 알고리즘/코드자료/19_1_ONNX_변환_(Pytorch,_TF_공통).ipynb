{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19-1. ONNX 변환 (Pytorch, TF 공통)",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJT5kqyZGe1p"
      },
      "source": [
        "# Fashion Mnist DNN ONNX 변환 Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzHP2rndF-0G"
      },
      "source": [
        "## 외부 파일 가져오기 & requirements 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi95dewjGeW_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "drive_project_root = \"/content/drive/MyDrive/#fastcampus\"\n",
        "sys.path.append(drive_project_root)\n",
        "!pip install -r \"/content/drive/MyDrive/#fastcampus/requirements.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFlvgHkj2wzZ"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = \"\\n\".join(gpu_info)\n",
        "print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9djS-LtvmwC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD7vyST9GdHv"
      },
      "source": [
        "from abc import abstractmethod\n",
        "from typing import Optional\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Union\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf import DictConfig\n",
        "import hydra\n",
        "from hydra.core.config_store import ConfigStore\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "from onnx_tf.backend import prepare\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch_optimizer import RAdam\n",
        "from torch_optimizer import AdamP\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX3soatAMk5B"
      },
      "source": [
        "from data_utils import dataset_split\n",
        "from config_utils import flatten_dict\n",
        "from config_utils import register_config\n",
        "from config_utils import configure_optimizers_from_cfg\n",
        "from config_utils import get_loggers\n",
        "from config_utils import get_callbacks\n",
        "from custom_math import softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwd5nW_3N37z"
      },
      "source": [
        "## 모델 (Multi-layer Perceptron) (MLP) ! 정의\n",
        "## 모델 MLPWithDropout 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNBF3WY_Z0rY"
      },
      "source": [
        "class BaseLightningModule(pl.LightningModule):\n",
        "    def __init__(self, cfg: DictConfig):\n",
        "        pl.LightningModule.__init__(self)\n",
        "        self.cfg = cfg\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "    \n",
        "    @abstractmethod\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        self._optimizers, self._schedulers = configure_optimizers_from_cfg(self.cfg, self)\n",
        "        return self._optimizers, self._schedulers\n",
        "    \n",
        "    def _forward(self, images, labels, mode: str):\n",
        "\n",
        "        assert mode in [\"train\", \"val\", \"test\"]\n",
        "\n",
        "        # get predictions\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # get loss (Loss 계산)\n",
        "        loss = self.loss_function(outputs, labels)\n",
        "        corrects = torch.sum(preds == labels.data)\n",
        "        acc = corrects / len(outputs)\n",
        "\n",
        "        return {\n",
        "            f\"{mode}_loss\": loss,\n",
        "            f\"{mode}_acc\": acc,\n",
        "        }, {\n",
        "            f\"{mode}_outputs\": outputs,\n",
        "            f\"{mode}_preds\": preds,\n",
        "            f\"{mode}_images\": images,\n",
        "            f\"{mode}_labels\": labels,\n",
        "            f\"{mode}_corrects\": corrects,\n",
        "        }\n",
        "\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        logs, _ = self._forward(images, labels, mode=\"train\")\n",
        "        self.log_dict(logs)\n",
        "        logs[\"loss\"] = logs[\"train_loss\"]\n",
        "        return logs\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        logs, _ = self._forward(images, labels, mode=\"val\")\n",
        "        self.log_dict(logs)\n",
        "        logs[\"loss\"] = logs[\"val_loss\"]\n",
        "        return logs\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        logs, logs_detail = self._forward(images, labels, mode=\"test\")\n",
        "        self.log_dict(logs)\n",
        "        logs[\"loss\"] = logs[\"test_loss\"]\n",
        "        logs.update(logs_detail)\n",
        "        return logs\n",
        "    \n",
        "    def test_epoch_end(self, step_end_outputs):\n",
        "        \n",
        "        model_outputs = torch.cat([o[\"test_outputs\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "        labels = torch.cat([o[\"test_labels\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "        preds = torch.cat([o[\"test_preds\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "        corrects = torch.cat([o[\"test_corrects\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "        losses = torch.cat([o[\"test_loss\"] for o in step_end_outputs]).detach().cpu().numpy()\n",
        "\n",
        "        final_outs = softmax(model_outputs, axis=1)\n",
        "\n",
        "        fpr = {}\n",
        "        tpr = {}\n",
        "        thresh = {}\n",
        "        n_class = self.cfg.data.n_class\n",
        "\n",
        "        for i in range(n_class):\n",
        "            fpr[i], tpr[i], thresh[i] = roc_curve(test_labels_list, model_outputs[:, i], pos_label=i)\n",
        "\n",
        "        # plot.\n",
        "        for i in range(n_class):\n",
        "            plt.plot(fpr[i], tpr[i], linestyle=\"--\", label=f\"Class {i} vs Rest\")\n",
        "        plt.title(\"Multi-class ROC Curve\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.legend(loc=\"best\")\n",
        "        # plt.show()\n",
        "\n",
        "        auc_score = roc_auc_score(\n",
        "            test_labels_list, test_outputs_list, multi_class=\"ovo\", average=\"macro\"\n",
        "        )\n",
        "\n",
        "        acc = corrects / len(corrects)\n",
        "        mean_loss = np.mean(losses)\n",
        "\n",
        "        return {\n",
        "            \"test_auc_score\": auc_score,\n",
        "            \"test_accuracy\": acc,\n",
        "            \"test_loss\": mean_loss\n",
        "        }\n",
        "    \n",
        "# TODO: add below things in the configs.\n",
        "# cfg.data.n_class\n",
        "# cfg.opt.lr_schedulers\n",
        "# cfg.opt.optimizers "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O--VMLMN04F"
      },
      "source": [
        "# Define Model.\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(in_dim, h1_dim)\n",
        "        self.linear2 = nn.Linear(h1_dim, h2_dim)\n",
        "        self.linear3 = nn.Linear(h2_dim, out_dim)\n",
        "        self.relu = F.relu\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input):\n",
        "        x = torch.flatten(input, start_dim=1)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        out = self.linear3(x)\n",
        "        # out = F.softmax(out)\n",
        "        return out\n",
        "\n",
        "class PLMLP(BaseLightningModule):\n",
        "    def __init__(self, cfg: DictConfig):\n",
        "        BaseLightningModule.__init__(self, cfg=cfg)\n",
        "        self.linear1 = nn.Linear(cfg.model.in_dim, cfg.model.h1_dim)\n",
        "        self.linear2 = nn.Linear(cfg.model.h1_dim, cfg.model.h2_dim)\n",
        "        self.linear3 = nn.Linear(cfg.model.h2_dim, cfg.model.out_dim)\n",
        "        self.relu = F.relu\n",
        "        pass\n",
        "    \n",
        "    def forward(self, input):\n",
        "        x = torch.flatten(input, start_dim=1)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        out = self.linear3(x)\n",
        "        # out = F.softmax(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MLPWithDropout(MLP):\n",
        "    def __init__(self, in_dim: int, h1_dim: int, h2_dim: int, out_dim: int, dropout_prob: float):\n",
        "        super().__init__(in_dim, h1_dim, h2_dim, out_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        x = torch.flatten(input, start_dim=1)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.dropout2(x)\n",
        "        out = self.linear3(x)\n",
        "        # out = F.softmax(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42in1xpAqQDY"
      },
      "source": [
        "## CNN 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCEx_VgEqTiB"
      },
      "source": [
        "_cnn_cfg_dict: dict = {\n",
        "    \"layer_1\": {\n",
        "        \"conv2d_in_channels\": 1,\n",
        "        \"conv2d_out_channels\": 32,\n",
        "        \"conv2d_kernel_size\": 3,\n",
        "        \"conv2d_padding\": 1,\n",
        "        \"maxpool2d_kernel_size\": 2,\n",
        "        \"maxpool2d_stride\": 2,\n",
        "    },\n",
        "    \"layer_2\": {\n",
        "        \"conv2d_in_channels\": 32,\n",
        "        \"conv2d_out_channels\": 64,\n",
        "        \"conv2d_kernel_size\": 3,\n",
        "        \"conv2d_padding\": 0,\n",
        "        \"maxpool2d_kernel_size\": 2,\n",
        "        \"maxpool2d_stride\": 1,\n",
        "    },\n",
        "    \"fc_1\": {\n",
        "        \"in_features\": 2304, #  수정 필요!\n",
        "        \"out_features\": 512,\n",
        "    },\n",
        "    \"fc_2\": {\n",
        "        \"in_features\": 512,\n",
        "        \"out_features\": 128,        \n",
        "    },\n",
        "    \"fc_3\": {\n",
        "        \"in_features\": 128,\n",
        "        \"out_features\": 10,\n",
        "    },\n",
        "    \"dropout_prob\": 0.25,\n",
        "}\n",
        "_cnn_cfg = OmegaConf.create(_cnn_cfg_dict)\n",
        "print(OmegaConf.to_yaml(_cnn_cfg))\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, cfg: DictConfig = _cnn_cfg):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=cfg.layer_1.conv2d_in_channels,\n",
        "                out_channels=cfg.layer_1.conv2d_out_channels,\n",
        "                kernel_size=cfg.layer_1.conv2d_kernel_size,\n",
        "                padding=cfg.layer_1.conv2d_padding\n",
        "            ),\n",
        "            nn.BatchNorm2d(cfg.layer_1.conv2d_out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=cfg.layer_1.maxpool2d_kernel_size,\n",
        "                stride=cfg.layer_1.maxpool2d_kernel_size\n",
        "            )\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=cfg.layer_2.conv2d_in_channels,\n",
        "                out_channels=cfg.layer_2.conv2d_out_channels,\n",
        "                kernel_size=cfg.layer_2.conv2d_kernel_size,\n",
        "                padding=cfg.layer_2.conv2d_padding\n",
        "            ),\n",
        "            nn.BatchNorm2d(cfg.layer_2.conv2d_out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=cfg.layer_2.maxpool2d_kernel_size,\n",
        "                stride=cfg.layer_2.maxpool2d_kernel_size\n",
        "            )\n",
        "        )\n",
        "        self.fc1 = nn.Linear(\n",
        "            in_features=cfg.fc_1.in_features,\n",
        "            out_features=cfg.fc_1.out_features,\n",
        "        )\n",
        "        self.fc2 = nn.Linear(\n",
        "            in_features=cfg.fc_2.in_features,\n",
        "            out_features=cfg.fc_2.out_features,\n",
        "        )\n",
        "        self.fc3 = nn.Linear(\n",
        "            in_features=cfg.fc_3.in_features,\n",
        "            out_features=cfg.fc_3.out_features,\n",
        "        )\n",
        "        self.dropout = nn.Dropout2d(cfg.dropout_prob)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVNk_qol3eCz"
      },
      "source": [
        "_efficient_finetune_cfg_dict: dict = {\n",
        "    \"efficient_net_model_name\": \"efficientnet-b1\",\n",
        "    \"num_classes\": 10\n",
        "}\n",
        "_efficient_finetune_cfg_cfg = OmegaConf.create(_efficient_finetune_cfg_dict)\n",
        "print(OmegaConf.to_yaml(_efficient_finetune_cfg_cfg))\n",
        "\n",
        "class EfficientNetFinetune(nn.Module):\n",
        "    def __init__(self, cfg: DictConfig = _efficient_finetune_cfg_cfg):\n",
        "        super().__init__()\n",
        "        self.efficientnet = EfficientNet.from_pretrained(\n",
        "            cfg.efficient_net_model_name,\n",
        "            cfg.num_classes\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.efficientnet(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMzKfPjHjQLb"
      },
      "source": [
        "# transform = transforms.Compose(\n",
        "#     [\n",
        "#         transforms.Resize(224),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "# data configs\n",
        "data_fashion_mnist_cfg = {\n",
        "    \"name\": \"fashion_mnist\",\n",
        "    \"data_root\": os.path.join(os.getcwd(), \"data\"),\n",
        "    \"W\": 28,\n",
        "    \"H\": 28,\n",
        "    \"C\": 1,\n",
        "    \"n_class\": 10,\n",
        "}\n",
        "\n",
        "# model configs \n",
        "model_mnist_mlp_cfg = {\n",
        "    \"name\": \"MLP\",\n",
        "    \"in_dim\": 28*28,\n",
        "    \"h1_dim\": 128,\n",
        "    \"h2_dim\": 64,\n",
        "    \"out_dim\": 10,\n",
        "    \"feature\": {\n",
        "        \"normalize\": {\n",
        "            \"mean\": [0.5],\n",
        "            \"std\": [0.5],\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# optimizer configs\n",
        "opt_cfg = {\n",
        "    \"optimizers\": [\n",
        "        {\n",
        "            \"name\": \"RAdam\",\n",
        "            \"kwargs\": {\n",
        "                \"lr\": 1e-3,\n",
        "                \"betas\": (0.9, 0.999),\n",
        "                \"eps\": 1e-8,\n",
        "                \"weight_decay\": 0,\n",
        "            },\n",
        "        }\n",
        "    ],\n",
        "    \"lr_schedulers\": [\n",
        "        {\n",
        "            \"name\": None,\n",
        "            \"kwargs\": {}\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "_merged_cfg_presets = {\n",
        "    \"mlp_fashion_mnist\": {\n",
        "        \"data\": data_fashion_mnist_cfg,\n",
        "        \"model\": model_mnist_mlp_cfg,\n",
        "        \"opt\": opt_cfg, \n",
        "    },\n",
        "}\n",
        "\n",
        "### hydra composition ###\n",
        "# clear hydra instance first\n",
        "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
        "\n",
        "# register preset configs\n",
        "register_config(_merged_cfg_presets)\n",
        "\n",
        "\n",
        "# initializing\n",
        "hydra.initialize(config_path=None)\n",
        "\n",
        "# compose\n",
        "cfg = hydra.compose(\"mlp_fashion_mnist\")\n",
        "\n",
        "###\n",
        "\n",
        "# override some cfg \n",
        "run_name = f\"{datetime.now().isoformat(timespec='seconds')}-{cfg.model.name}-{cfg.data.name}\"\n",
        "\n",
        "\n",
        "## Define train configs\n",
        "project_root_dir = os.path.join(\n",
        "    drive_project_root, \"runs\", \"dnn-tutorial-fashion-mnist-runs\"\n",
        ")\n",
        "save_dir = os.path.join(project_root_dir, run_name)\n",
        "run_root_dir = os.path.join(project_root_dir, run_name)\n",
        "\n",
        "# train configs\n",
        "train_cfg = {\n",
        "    \"train_batch_size\": 128,\n",
        "    \"val_batch_size\": 32,\n",
        "    \"test_batch_size\": 32,\n",
        "    \"train_val_split\": [0.9, 0.1],\n",
        "    \"run_root_dir\": run_root_dir,\n",
        "    \"trainer_kwargs\": {\n",
        "        \"accelerator\": \"dp\",\n",
        "        \"gpus\": \"0\",\n",
        "        \"max_epochs\": 50,\n",
        "        \"val_check_interval\": 1.0,\n",
        "        \"log_every_n_steps\": 100,\n",
        "        \"flush_logs_every_n_steps\": 100,\n",
        "    }\n",
        "}\n",
        "\n",
        "# logger configs \n",
        "log_cfg = {\n",
        "    \"loggers\": {\n",
        "        \"WandbLogger\": {\n",
        "            \"project\": \"fastcampus_fashion_mnist_tutorials\",\n",
        "            \"name\": run_name,\n",
        "            \"tags\": [\"fastcampus_fashion_mnist_tutorials\"],\n",
        "            \"save_dir\": run_root_dir,\n",
        "        },\n",
        "        \"TensorBoardLogger\": {\n",
        "            \"save_dir\": project_root_dir,\n",
        "            \"name\": run_name,\n",
        "        }\n",
        "    },\n",
        "    \"callbacks\": {\n",
        "        \"ModelCheckpoint\": {\n",
        "            \"save_top_k\": 3,\n",
        "            \"monitor\": \"val_loss\",\n",
        "            \"mode\": \"min\",\n",
        "            \"verbose\": True,\n",
        "            \"dirpath\": os.path.join(run_root_dir, \"weights\"),\n",
        "            \"filename\": \"{epoch}-{val_loss:.3f}-{val_acc:.3f}\"\n",
        "        },\n",
        "        \"EarlyStopping\": {\n",
        "            \"monitor\": \"val_loss\",\n",
        "            \"mode\": \"min\",\n",
        "            \"patience\": 3,\n",
        "            \"verbose\": True,\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# unlock config & set train, log confg\n",
        "OmegaConf.set_struct(cfg, False)\n",
        "cfg.train = train_cfg\n",
        "cfg.log = log_cfg\n",
        "\n",
        "# lock config\n",
        "OmegaConf.set_struct(cfg, True)\n",
        "print(OmegaConf.to_yaml(cfg))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NOm5_pPsQwx"
      },
      "source": [
        "data_root = cfg.data.data_root\n",
        "\n",
        "# 전처리 부분 (preprocessing) & 데이터 셋 정의.\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            cfg.model.feature.normalize.mean,\n",
        "            cfg.model.feature.normalize.std,\n",
        "        ), # mean, # std\n",
        "    ]\n",
        ")\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [\n",
        "#         transforms.Resize(cfg.data.W*cfg.data.H*cfg.data.C),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "fashion_mnist_dataset = FashionMNIST(data_root, download=True, train=True, transform=transform)\n",
        "test_dataset = FashionMNIST(data_root, download=True, train=False, transform=transform)\n",
        "\n",
        "datasets = dataset_split(fashion_mnist_dataset, split=cfg.train.train_val_split)\n",
        "\n",
        "train_dataset = datasets[\"train\"]\n",
        "val_dataset = datasets[\"val\"]\n",
        "\n",
        "train_batch_size = cfg.train.train_batch_size\n",
        "val_batch_size = cfg.train.val_batch_size\n",
        "test_batch_size = cfg.train.test_batch_size\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=0\n",
        ")\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=val_batch_size, shuffle=False, num_workers=0\n",
        ")\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=val_batch_size, shuffle=False, num_workers=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8tljBSaQBZB"
      },
      "source": [
        "## 모델 선언 및 손실 함수, 최적화(Optimizer) 정의, Tensorboard Logger 정의 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8p_hsjsO-on"
      },
      "source": [
        "# model define\n",
        "\n",
        "def get_pl_model(cfg: DictConfig, checkpoint_path: Optional[str] = None):\n",
        "\n",
        "    if cfg.model.name == \"MLP\":\n",
        "        model = PLMLP(cfg)\n",
        "    else:\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    if checkpoint_path is not None:\n",
        "        model = model.load_from_checkpoint(cfg=cfg, checkpoint_path=checkpoint_path)\n",
        "    return model\n",
        "\n",
        "model = get_pl_model(cfg)\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nTzE40svgsB"
      },
      "source": [
        "logger = get_loggers(cfg)\n",
        "callbacks = get_callbacks(cfg)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    callbacks=callbacks,\n",
        "    logger=logger,\n",
        "    default_root_dir=cfg.train.run_root_dir,\n",
        "    num_sanity_val_steps=2,\n",
        "    **cfg.train.trainer_kwargs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b93vvDdCv9LZ"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/\\#fastcampus/runs/dnn-tutorial-fashion-mnist-runs/\n",
        "\n",
        "trainer.fit(model, train_dataloader, val_dataloader)\n",
        "# trainer.test(model, test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMKzuQkAseVn"
      },
      "source": [
        "# Config file 저장\n",
        "OmegaConf.save(cfg, os.path.join(run_root_dir, \"config.yaml\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0unhP3i4s2ao"
      },
      "source": [
        "# 서비스 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm5jZ7urbMAO"
      },
      "source": [
        "loaded_cfg = OmegaConf.load(os.path.join(run_root_dir, \"config.yaml\"))\n",
        "\n",
        "log_model_path = run_root_dir\n",
        "model_path = os.path.join(\n",
        "    log_model_path,\n",
        "    \"weights\",\n",
        "    \"epoch=1-val_loss=0.420-val_acc=0.848.ckpt\"\n",
        ")\n",
        "\n",
        "loaded_model = PLMLP.load_from_checkpoint(model_path, cfg=loaded_cfg)\n",
        "loaded_model.cpu()\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICY_m4xytWh4"
      },
      "source": [
        "## Pytorch --> Onnx 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aENlPdjtWMd"
      },
      "source": [
        "onnx_path = os.path.join(log_model_path, \"plmlp.onnx\")\n",
        "loaded_model.to_onnx(\n",
        "    onnx_path,\n",
        "    input_sample=test_dataset[0][0],\n",
        "    input_names=[\"imgs\"],\n",
        "    output_names=[\"logits\"],\n",
        "    opset_version=11,\n",
        "    dynamic_axes={\"imgs\": {0: \"batch\"}},\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHaMzI1etI7X"
      },
      "source": [
        "# testing \n",
        "ort_sess = ort.InferenceSession(onnx_path)\n",
        "print(ort_sess.get_modelmeta())\n",
        "\n",
        "inputs = [i.name for i in ort_sess.get_inputs()]\n",
        "outputs = [i.name for i in ort_sess.get_outputs()]\n",
        "print(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLmI9sv4u-g3"
      },
      "source": [
        "# onnx result\n",
        "onnx_res = ort_sess.run([], {\"imgs\": test_dataset[0][0].cpu().numpy()})\n",
        "# pl torch model result\n",
        "model_res = loaded_model(test_dataset[0][0]).cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dVKvgVyvrYB"
      },
      "source": [
        "# validation\n",
        "assert np.isclose(onnx_res[0], model_res).all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NuHyxyeywIn"
      },
      "source": [
        "## ONNX to TF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDH-Il8pww68"
      },
      "source": [
        "# export to tensorflow from onnx\n",
        "output_tf_path = os.path.join(log_model_path, \"tf_model.pb\")\n",
        "onnx_model = onnx.load(onnx_path)\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph(output_tf_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1SRmUFqz0V7"
      },
      "source": [
        "# tf model load & get outputs\n",
        "tf_model = tf.saved_model.load(output_tf_path)\n",
        "tf_outputs = tf_model(imgs=test_dataset[0][0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKQtMGSj0T94"
      },
      "source": [
        "# validation\n",
        "assert np.isclose(tf_outputs[\"logits\"].numpy(), model_res).all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdb9Xj6p1URo"
      },
      "source": [
        "## From TF to Onnx\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1Q950k0qNI"
      },
      "source": [
        "onnx_from_tf_path = os.path.join(log_model_path, \"from_tf.onnx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52hXL8nb1b7R"
      },
      "source": [
        "!python -m tf2onnx.convert --saved-model $output_tf_path --opset 11 --output $onnx_from_tf_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbg_biKV2a_W"
      },
      "source": [
        "ort_sess = ort.InferenceSession(onnx_from_tf_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2s9OxZ63DoW"
      },
      "source": [
        "# validation\n",
        "onnx_last_res = ort_sess.run([], {\"imgs\": test_dataset[0][0].cpu().numpy()})\n",
        "assert np.isclose(onnx_last_res[0], model_res).all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iTgD1tK3Sgq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}